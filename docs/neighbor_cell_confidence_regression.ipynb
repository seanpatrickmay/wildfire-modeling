{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2d92e88",
   "metadata": {},
   "source": [
    "## 0) Variable meanings\n",
    "\n",
    "- **Target** = center-cell GOES fire confidence at time `t+1`, converted to binary class\n",
    "- **Positive class (1)** = `confidence_t+1 >= 0.10`\n",
    "- **Negative class (0)** = `confidence_t+1 < 0.10`\n",
    "- **Cell features** = all available cell data at time `t` for center cell + surrounding 8 cells\n",
    "- **Variables per cell**:\n",
    "  - `fire_confidence` (GOES fire confidence at current hour)\n",
    "  - `temperature` (RTMA near-surface temperature, raw key `TMP`)\n",
    "  - `wind_speed` (RTMA wind speed, raw key `WIND`)\n",
    "  - `specific_humidity` (RTMA specific humidity, raw key `SPFH`)\n",
    "  - `precipitation_1h` (RTMA 1-hour accumulated precipitation, raw key `ACPC01`)\n",
    "  - `wind_direction_sin` (sine of RTMA wind direction in radians)\n",
    "  - `wind_direction_cos` (cosine of RTMA wind direction in radians)\n",
    "- **Cell order** = `C, NW, N, NE, W, E, SW, S, SE`\n",
    "- **Model** = logistic regression (streaming SGD optimization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25198aba",
   "metadata": {},
   "source": [
    "## 1) Summary\n",
    "\n",
    "- Data: GOES hourly confidence (~2 km) + RTMA hourly meteorology\n",
    "- Task: predict whether next-hour center-cell confidence crosses 0.10 using center + 8-neighbor features at current hour\n",
    "- Wind direction features: encoded as `sin` and `cos` (no raw degree feature)\n",
    "- Split: complete-fire holdout (train on full fires, test on different full fires)\n",
    "- Feature normalization: z-score normalization using train-fire statistics only\n",
    "- Training: logistic regression on normalized train-fire features only\n",
    "- Evaluation: held-out test-fire set `test_accuracy_overall`, `test_positive_accuracy`, `test_negative_accuracy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43ba7b",
   "metadata": {},
   "source": [
    "## 2) Section toggles\n",
    "\n",
    "Use this block to quickly enable/disable major notebook sections.\n",
    "\n",
    "Dependency notes:\n",
    "- `RUN_TRAINING_SECTION` requires fire discovery + helper definitions.\n",
    "- `RUN_EVALUATION_SECTION` requires a trained model.\n",
    "- `RUN_PR_SECTION` and `RUN_COEFFICIENT_SECTION` require a trained model.\n",
    "- `RUN_SUMMARY_SECTION` and `RUN_REPORT_SECTION` expect prior sections to have produced metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3b72f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Fire selection:\n",
    "# - \"all\" => use every fire in data/multi_fire/*\n",
    "# - list => use only named fires, e.g. [\"Creek\", \"Dixie\"]\n",
    "FIRE_SELECTION = \"all\"\n",
    "\n",
    "# Fire-level train/test split settings.\n",
    "# - If TRAIN_FIRES and TEST_FIRES are both \"auto\": split selected fires by FIRE_TRAIN_FRACTION\n",
    "# - If one side is \"auto\" and the other is a list: auto side gets remaining fires\n",
    "# - If both are lists: both lists are used exactly\n",
    "TRAIN_FIRES = \"auto\"\n",
    "TEST_FIRES = \"auto\"\n",
    "FIRE_TRAIN_FRACTION = 0.70\n",
    "FIRE_SPLIT_SEED = 42\n",
    "\n",
    "# Classification settings.\n",
    "POSITIVE_THRESHOLD = 0.10\n",
    "CLASSIFICATION_PROB_THRESHOLD = 0.50\n",
    "\n",
    "# Feature scaling settings.\n",
    "NORMALIZE_FEATURES = True\n",
    "\n",
    "# Section toggles.\n",
    "RUN_FIRE_DISCOVERY_SECTION = True\n",
    "RUN_DATA_STATS_SECTION = True\n",
    "RUN_NORMALIZATION_SECTION = True\n",
    "RUN_TRAINING_SECTION = True\n",
    "RUN_EVALUATION_SECTION = True\n",
    "RUN_SUMMARY_SECTION = True\n",
    "RUN_PR_SECTION = True\n",
    "RUN_COEFFICIENT_SECTION = True\n",
    "RUN_REPORT_SECTION = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0de44400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /Users/seanmay/Desktop/Current Projects/wildfire-prediction/docs\n",
      "fire selection: all\n",
      "train fires config: auto\n",
      "test fires config: auto\n",
      "fire train fraction (auto mode): 0.7\n",
      "fire split seed: 42\n",
      "positive confidence threshold: 0.1\n",
      "classification probability threshold: 0.5\n",
      "normalize features: True\n",
      "section toggles:\n",
      "  fire discovery: True\n",
      "  data stats: True\n",
      "  normalization: True\n",
      "  training: True\n",
      "  evaluation: True\n",
      "  summary: True\n",
      "  precision-recall: True\n",
      "  coefficients: True\n",
      "  report: True\n"
     ]
    }
   ],
   "source": [
    "print(\"cwd:\", Path.cwd())\n",
    "print(\"fire selection:\", FIRE_SELECTION)\n",
    "print(\"train fires config:\", TRAIN_FIRES)\n",
    "print(\"test fires config:\", TEST_FIRES)\n",
    "print(\"fire train fraction (auto mode):\", FIRE_TRAIN_FRACTION)\n",
    "print(\"fire split seed:\", FIRE_SPLIT_SEED)\n",
    "print(\"positive confidence threshold:\", POSITIVE_THRESHOLD)\n",
    "print(\"classification probability threshold:\", CLASSIFICATION_PROB_THRESHOLD)\n",
    "print(\"normalize features:\", NORMALIZE_FEATURES)\n",
    "print(\"section toggles:\")\n",
    "print(\"  fire discovery:\", RUN_FIRE_DISCOVERY_SECTION)\n",
    "print(\"  data stats:\", RUN_DATA_STATS_SECTION)\n",
    "print(\"  normalization:\", RUN_NORMALIZATION_SECTION)\n",
    "print(\"  training:\", RUN_TRAINING_SECTION)\n",
    "print(\"  evaluation:\", RUN_EVALUATION_SECTION)\n",
    "print(\"  summary:\", RUN_SUMMARY_SECTION)\n",
    "print(\"  precision-recall:\", RUN_PR_SECTION)\n",
    "print(\"  coefficients:\", RUN_COEFFICIENT_SECTION)\n",
    "print(\"  report:\", RUN_REPORT_SECTION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc1297",
   "metadata": {},
   "source": [
    "## 3) Imports and generic helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d818ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.warp import Resampling, reproject\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "544ad56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_iso(value: str) -> datetime:\n",
    "    if value.endswith(\"Z\"):\n",
    "        value = value[:-1] + \"+00:00\"\n",
    "    return datetime.fromisoformat(value)\n",
    "\n",
    "\n",
    "def normalize_time_str(value: str) -> str:\n",
    "    dt = parse_iso(value)\n",
    "    return dt.strftime(\"%Y-%m-%dT%H:00:00Z\")\n",
    "\n",
    "\n",
    "def affine_from_list(vals: list) -> rasterio.Affine:\n",
    "    return rasterio.Affine(vals[0], vals[1], vals[2], vals[3], vals[4], vals[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3a9170f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo root: /Users/seanmay/Desktop/Current Projects/wildfire-prediction\n"
     ]
    }
   ],
   "source": [
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data\").exists() and (p / \"scripts\").exists() and (p / \"docs\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Could not find repo root containing data/, scripts/, docs/.\")\n",
    "\n",
    "\n",
    "def load_goes_times(goes_meta: dict, goes_conf: np.ndarray):\n",
    "    goes_time_steps = goes_meta.get(\"time_steps\", [])\n",
    "    goes_start = goes_meta.get(\"start_time\")\n",
    "\n",
    "    if goes_time_steps and isinstance(goes_time_steps[0], (int, float)):\n",
    "        if not goes_start:\n",
    "            raise ValueError(\"GOES time_steps are numeric and metadata.start_time is missing.\")\n",
    "        start_dt = parse_iso(goes_start)\n",
    "        goes_time_steps = [\n",
    "            (start_dt + timedelta(hours=int(i - 1))).strftime(\"%Y-%m-%dT%H:00:00Z\")\n",
    "            for i in goes_time_steps\n",
    "        ]\n",
    "    elif not goes_time_steps and goes_start:\n",
    "        start_dt = parse_iso(goes_start)\n",
    "        goes_time_steps = [\n",
    "            (start_dt + timedelta(hours=i)).strftime(\"%Y-%m-%dT%H:00:00Z\")\n",
    "            for i in range(goes_conf.shape[0])\n",
    "        ]\n",
    "    else:\n",
    "        goes_time_steps = [normalize_time_str(t) for t in goes_time_steps]\n",
    "\n",
    "    if not goes_time_steps:\n",
    "        raise ValueError(\"GOES metadata has no usable time_steps.\")\n",
    "\n",
    "    return goes_time_steps\n",
    "\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "print(\"repo root:\", REPO_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16873bd3",
   "metadata": {},
   "source": [
    "## 4) Fire discovery and split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ed484915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_fire_entries(repo_root: Path):\n",
    "    base = repo_root / \"data\" / \"multi_fire\"\n",
    "    if not base.exists():\n",
    "        raise FileNotFoundError(f\"Missing multi-fire directory: {base}\")\n",
    "\n",
    "    entries = []\n",
    "    for fire_dir in sorted([d for d in base.iterdir() if d.is_dir()]):\n",
    "        goes_candidates = sorted(fire_dir.glob(\"*GOES*json\"))\n",
    "        manifest_path = fire_dir / \"rtma\" / \"rtma_manifest.json\"\n",
    "        if not goes_candidates or not manifest_path.exists():\n",
    "            continue\n",
    "        entries.append(\n",
    "            {\n",
    "                \"fire_name\": fire_dir.name,\n",
    "                \"goes_json\": goes_candidates[0],\n",
    "                \"rtma_manifest\": manifest_path,\n",
    "            }\n",
    "        )\n",
    "    return entries\n",
    "\n",
    "\n",
    "def select_fire_entries(entries, fire_selection):\n",
    "    if fire_selection is None or fire_selection == \"all\":\n",
    "        return entries\n",
    "\n",
    "    if not isinstance(fire_selection, (list, tuple, set)):\n",
    "        raise ValueError('FIRE_SELECTION must be \"all\" or a list/tuple/set of fire names.')\n",
    "\n",
    "    wanted = {str(x) for x in fire_selection}\n",
    "    selected = [e for e in entries if e[\"fire_name\"] in wanted]\n",
    "    found = {e[\"fire_name\"] for e in selected}\n",
    "    missing = sorted(wanted - found)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Unknown fire names in FIRE_SELECTION: {missing}\")\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3eac5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fire_entries(entries, train_fires, test_fires, train_fraction, split_seed):\n",
    "    if len(entries) < 2:\n",
    "        raise ValueError(\"Need at least 2 selected fires for fire-level train/test split.\")\n",
    "\n",
    "    names = [e[\"fire_name\"] for e in entries]\n",
    "    name_set = set(names)\n",
    "\n",
    "    def normalize_group(value):\n",
    "        if value is None or value == \"auto\":\n",
    "            return \"auto\"\n",
    "        if not isinstance(value, (list, tuple, set)):\n",
    "            raise ValueError(\"TRAIN_FIRES/TEST_FIRES must be 'auto' or list/tuple/set of fire names.\")\n",
    "        normalized = [str(x) for x in value]\n",
    "        unknown = sorted(set(normalized) - name_set)\n",
    "        if unknown:\n",
    "            raise ValueError(f\"Unknown fire names in train/test split: {unknown}\")\n",
    "        return normalized\n",
    "\n",
    "    train_group = normalize_group(train_fires)\n",
    "    test_group = normalize_group(test_fires)\n",
    "\n",
    "    if train_group == \"auto\" and test_group == \"auto\":\n",
    "        if not (0.0 < train_fraction < 1.0):\n",
    "            raise ValueError(\"FIRE_TRAIN_FRACTION must be between 0 and 1.\")\n",
    "        rng = np.random.default_rng(split_seed)\n",
    "        perm_names = list(np.array(names)[rng.permutation(len(names))])\n",
    "        n_train = int(round(train_fraction * len(perm_names)))\n",
    "        n_train = max(1, min(len(perm_names) - 1, n_train))\n",
    "        train_names = set(perm_names[:n_train])\n",
    "        test_names = set(perm_names[n_train:])\n",
    "    elif train_group == \"auto\":\n",
    "        test_names = set(test_group)\n",
    "        train_names = set(names) - test_names\n",
    "    elif test_group == \"auto\":\n",
    "        train_names = set(train_group)\n",
    "        test_names = set(names) - train_names\n",
    "    else:\n",
    "        train_names = set(train_group)\n",
    "        test_names = set(test_group)\n",
    "\n",
    "    overlap = sorted(train_names & test_names)\n",
    "    if overlap:\n",
    "        raise ValueError(f\"Train/test fire sets overlap: {overlap}\")\n",
    "    if len(train_names) == 0:\n",
    "        raise ValueError(\"Train fire set is empty.\")\n",
    "    if len(test_names) == 0:\n",
    "        raise ValueError(\"Test fire set is empty.\")\n",
    "\n",
    "    train_entries = [e for e in entries if e[\"fire_name\"] in train_names]\n",
    "    test_entries = [e for e in entries if e[\"fire_name\"] in test_names]\n",
    "    return train_entries, test_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "85302bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fires: ['Antelope', 'August_Complex', 'Beckwourth_Complex', 'Bobcat', 'CZU_Lightning_Complex', 'Caldor', 'Creek', 'Dixie', 'Dolan', 'Glass', 'July_Complex', 'KNP_Complex', 'Kincade', 'LNU_Lightning_Complex', 'McCash', 'McFarland', 'Monument', 'North_Complex', 'Red_Salmon_Complex', 'River_Complex', 'SCU_Lightning_Complex', 'SQF_Complex', 'Slater_and_Devil', 'Tamarack', 'W-5_Cold_Springs', 'Walker', 'Windy', 'Zogg']\n",
      "Selected fires: ['Antelope', 'August_Complex', 'Beckwourth_Complex', 'Bobcat', 'CZU_Lightning_Complex', 'Caldor', 'Creek', 'Dixie', 'Dolan', 'Glass', 'July_Complex', 'KNP_Complex', 'Kincade', 'LNU_Lightning_Complex', 'McCash', 'McFarland', 'Monument', 'North_Complex', 'Red_Salmon_Complex', 'River_Complex', 'SCU_Lightning_Complex', 'SQF_Complex', 'Slater_and_Devil', 'Tamarack', 'W-5_Cold_Springs', 'Walker', 'Windy', 'Zogg']\n",
      "Train fires: ['Antelope', 'Bobcat', 'Caldor', 'Creek', 'Dixie', 'Glass', 'July_Complex', 'KNP_Complex', 'Kincade', 'McFarland', 'Monument', 'North_Complex', 'Red_Salmon_Complex', 'River_Complex', 'SCU_Lightning_Complex', 'SQF_Complex', 'Slater_and_Devil', 'Tamarack', 'W-5_Cold_Springs', 'Zogg']\n",
      "Test fires: ['August_Complex', 'Beckwourth_Complex', 'CZU_Lightning_Complex', 'Dolan', 'LNU_Lightning_Complex', 'McCash', 'Walker', 'Windy']\n"
     ]
    }
   ],
   "source": [
    "all_fire_entries = []\n",
    "fire_entries = []\n",
    "train_fire_entries = []\n",
    "test_fire_entries = []\n",
    "\n",
    "if RUN_FIRE_DISCOVERY_SECTION:\n",
    "    all_fire_entries = discover_fire_entries(REPO_ROOT)\n",
    "    fire_entries = select_fire_entries(all_fire_entries, FIRE_SELECTION)\n",
    "    train_fire_entries, test_fire_entries = split_fire_entries(\n",
    "        fire_entries,\n",
    "        TRAIN_FIRES,\n",
    "        TEST_FIRES,\n",
    "        FIRE_TRAIN_FRACTION,\n",
    "        FIRE_SPLIT_SEED,\n",
    "    )\n",
    "\n",
    "    print(\"Available fires:\", [e[\"fire_name\"] for e in all_fire_entries])\n",
    "    print(\"Selected fires:\", [e[\"fire_name\"] for e in fire_entries])\n",
    "    print(\"Train fires:\", [e[\"fire_name\"] for e in train_fire_entries])\n",
    "    print(\"Test fires:\", [e[\"fire_name\"] for e in test_fire_entries])\n",
    "\n",
    "    if len(fire_entries) == 0:\n",
    "        raise RuntimeError(\"No fires selected.\")\n",
    "else:\n",
    "    print(\"Skipped fire discovery/split section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f78d1",
   "metadata": {},
   "source": [
    "## 5) Feature schema and sample building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d0efb212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature count: 63\n",
      "first 10 feature names: ['fire_confidence_c', 'temperature_c', 'wind_speed_c', 'specific_humidity_c', 'precipitation_1h_c', 'wind_direction_sin_c', 'wind_direction_cos_c', 'fire_confidence_nw', 'temperature_nw', 'wind_speed_nw']\n"
     ]
    }
   ],
   "source": [
    "CELL_OFFSETS = [\n",
    "    (\"c\", 0, 0),\n",
    "    (\"nw\", -1, -1),\n",
    "    (\"n\", -1, 0),\n",
    "    (\"ne\", -1, 1),\n",
    "    (\"w\", 0, -1),\n",
    "    (\"e\", 0, 1),\n",
    "    (\"sw\", 1, -1),\n",
    "    (\"s\", 1, 0),\n",
    "    (\"se\", 1, 1),\n",
    "]\n",
    "VAR_ORDER = [\"fire_confidence\", \"temperature\", \"wind_speed\", \"specific_humidity\", \"precipitation_1h\", \"wind_direction_sin\", \"wind_direction_cos\"]\n",
    "RTMA_VARS_REQUIRED = [\"TMP\", \"WIND\", \"WDIR\", \"SPFH\", \"ACPC01\"]\n",
    "\n",
    "\n",
    "def feature_names():\n",
    "    names = []\n",
    "    for n_name, _, _ in CELL_OFFSETS:\n",
    "        for v in VAR_ORDER:\n",
    "            names.append(f\"{v}_{n_name}\")\n",
    "    return names\n",
    "\n",
    "\n",
    "FEATURE_NAMES = feature_names()\n",
    "N_FEATURES = len(FEATURE_NAMES)\n",
    "\n",
    "\n",
    "print(\"feature count:\", N_FEATURES)\n",
    "print(\"first 10 feature names:\", FEATURE_NAMES[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "03b9256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary_target(y_continuous: np.ndarray, threshold: float) -> np.ndarray:\n",
    "    return (y_continuous >= threshold).astype(np.int32)\n",
    "\n",
    "\n",
    "def resolve_manifest_file_path(path_str: str, repo_root: Path, manifest_dir: Path) -> Path:\n",
    "    p = Path(path_str).expanduser()\n",
    "    if p.exists():\n",
    "        return p\n",
    "\n",
    "    parts = p.parts\n",
    "    if \"data\" in parts:\n",
    "        idx = parts.index(\"data\")\n",
    "        candidate = repo_root.joinpath(*parts[idx:])\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "\n",
    "    candidate = (manifest_dir / path_str).resolve()\n",
    "    if candidate.exists():\n",
    "        return candidate\n",
    "\n",
    "    raise FileNotFoundError(f\"Could not resolve RTMA part path: {path_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f60db9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_stack(src_stack, src_transform, src_crs, dst_shape, dst_transform, dst_crs):\n",
    "    bands = src_stack.shape[0]\n",
    "    dst = np.empty((bands, dst_shape[0], dst_shape[1]), dtype=np.float32)\n",
    "    for b in range(bands):\n",
    "        reproject(\n",
    "            source=src_stack[b],\n",
    "            destination=dst[b],\n",
    "            src_transform=src_transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.bilinear,\n",
    "        )\n",
    "    return dst\n",
    "\n",
    "\n",
    "def build_hour_samples(conf_t, conf_t1, rtma_hour):\n",
    "    h, w = conf_t.shape\n",
    "    if h < 3 or w < 3:\n",
    "        return np.empty((0, N_FEATURES), dtype=np.float64), np.empty((0,), dtype=np.float64)\n",
    "\n",
    "    y = conf_t1[1:-1, 1:-1].astype(np.float64)\n",
    "    feat_blocks = []\n",
    "\n",
    "    for _, dy, dx in CELL_OFFSETS:\n",
    "        ys = slice(1 + dy, h - 1 + dy)\n",
    "        xs = slice(1 + dx, w - 1 + dx)\n",
    "\n",
    "        go_cell = conf_t[ys, xs].astype(np.float64)\n",
    "        tmp_cell = rtma_hour[\"TMP\"][ys, xs].astype(np.float64)\n",
    "        wind_cell = rtma_hour[\"WIND\"][ys, xs].astype(np.float64)\n",
    "        spfh_cell = rtma_hour[\"SPFH\"][ys, xs].astype(np.float64)\n",
    "        precip_cell = rtma_hour[\"ACPC01\"][ys, xs].astype(np.float64)\n",
    "        wdir_deg_cell = rtma_hour[\"WDIR\"][ys, xs].astype(np.float64)\n",
    "        wdir_rad_cell = np.deg2rad(wdir_deg_cell)\n",
    "        wdir_sin_cell = np.sin(wdir_rad_cell)\n",
    "        wdir_cos_cell = np.cos(wdir_rad_cell)\n",
    "\n",
    "        feat_blocks.extend([\n",
    "            go_cell,\n",
    "            tmp_cell,\n",
    "            wind_cell,\n",
    "            spfh_cell,\n",
    "            precip_cell,\n",
    "            wdir_sin_cell,\n",
    "            wdir_cos_cell,\n",
    "        ])\n",
    "\n",
    "    X = np.stack(feat_blocks, axis=-1).reshape(-1, N_FEATURES)\n",
    "    y = y.reshape(-1)\n",
    "\n",
    "    valid = np.isfinite(y)\n",
    "    valid &= np.isfinite(X).all(axis=1)\n",
    "\n",
    "    if not valid.any():\n",
    "        return np.empty((0, N_FEATURES), dtype=np.float64), np.empty((0,), dtype=np.float64)\n",
    "\n",
    "    return X[valid], y[valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3775cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_aligned_hours_for_fire(\n",
    "    goes_conf,\n",
    "    goes_time_index,\n",
    "    rtma_manifest,\n",
    "    rtma_manifest_path: Path,\n",
    "    goes_shape,\n",
    "    goes_transform,\n",
    "    goes_crs,\n",
    "):\n",
    "    rtma_vars = rtma_manifest[\"variables\"]\n",
    "    for req in RTMA_VARS_REQUIRED:\n",
    "        if req not in rtma_vars:\n",
    "            raise KeyError(f\"RTMA manifest missing required variable: {req}\")\n",
    "\n",
    "    manifest_dir = rtma_manifest_path.parent\n",
    "    rtma_files = rtma_manifest[\"files\"]\n",
    "    resolved_files = {\n",
    "        var: [resolve_manifest_file_path(path, REPO_ROOT, manifest_dir) for path in rtma_files[var]]\n",
    "        for var in rtma_vars\n",
    "    }\n",
    "\n",
    "    n_parts = len(resolved_files[rtma_vars[0]])\n",
    "    for v in rtma_vars:\n",
    "        if len(resolved_files[v]) != n_parts:\n",
    "            raise ValueError(\"RTMA variable file lists do not have equal part counts.\")\n",
    "\n",
    "    parts = list(zip(*[resolved_files[v] for v in rtma_vars]))\n",
    "    rtma_time_steps = [normalize_time_str(t) for t in rtma_manifest[\"time_steps\"]]\n",
    "\n",
    "    rtma_time_ptr = 0\n",
    "\n",
    "    for part_paths in parts:\n",
    "        rtma_arrays = {}\n",
    "        rtma_transform = None\n",
    "        rtma_crs = None\n",
    "        band_count = None\n",
    "\n",
    "        for var, part_path in zip(rtma_vars, part_paths):\n",
    "            with rasterio.open(part_path) as ds:\n",
    "                if rtma_transform is None:\n",
    "                    rtma_transform = ds.transform\n",
    "                    rtma_crs = ds.crs\n",
    "                    band_count = ds.count\n",
    "                rtma_arrays[var] = ds.read().astype(\"float32\")\n",
    "\n",
    "        if band_count is None:\n",
    "            continue\n",
    "\n",
    "        resampled = {}\n",
    "        for var in rtma_vars:\n",
    "            resampled[var] = resample_stack(\n",
    "                rtma_arrays[var],\n",
    "                rtma_transform,\n",
    "                rtma_crs,\n",
    "                goes_shape,\n",
    "                goes_transform,\n",
    "                goes_crs,\n",
    "            )\n",
    "\n",
    "        for local_idx in range(band_count):\n",
    "            global_idx = rtma_time_ptr + local_idx\n",
    "            if global_idx >= len(rtma_time_steps):\n",
    "                break\n",
    "\n",
    "            time_str = rtma_time_steps[global_idx]\n",
    "            if time_str not in goes_time_index:\n",
    "                continue\n",
    "\n",
    "            t = goes_time_index[time_str]\n",
    "            if t + 1 >= goes_conf.shape[0]:\n",
    "                continue\n",
    "\n",
    "            rtma_hour = {var: resampled[var][local_idx] for var in RTMA_VARS_REQUIRED}\n",
    "            yield t, rtma_hour\n",
    "\n",
    "        rtma_time_ptr += band_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0327ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_fire_hour_samples(entry):\n",
    "    with Path(entry[\"goes_json\"]).open(\"r\", encoding=\"utf-8\") as f:\n",
    "        goes_json_local = json.load(f)\n",
    "    with Path(entry[\"rtma_manifest\"]).open(\"r\", encoding=\"utf-8\") as f:\n",
    "        rtma_manifest_local = json.load(f)\n",
    "\n",
    "    goes_conf_local = np.array(goes_json_local[\"data\"], dtype=np.float32)\n",
    "    goes_meta_local = goes_json_local[\"metadata\"]\n",
    "    goes_transform_local = affine_from_list(goes_meta_local[\"geo_transform\"])\n",
    "    goes_crs_local = goes_meta_local.get(\"crs\")\n",
    "    goes_shape_local = tuple(goes_meta_local[\"grid_shape\"])\n",
    "    goes_times_local = load_goes_times(goes_meta_local, goes_conf_local)\n",
    "    goes_time_index_local = {t: i for i, t in enumerate(goes_times_local)}\n",
    "\n",
    "    for t, rtma_hour in iter_aligned_hours_for_fire(\n",
    "        goes_conf_local,\n",
    "        goes_time_index_local,\n",
    "        rtma_manifest_local,\n",
    "        Path(entry[\"rtma_manifest\"]),\n",
    "        goes_shape_local,\n",
    "        goes_transform_local,\n",
    "        goes_crs_local,\n",
    "    ):\n",
    "        X_hour, y_hour_cont = build_hour_samples(goes_conf_local[t], goes_conf_local[t + 1], rtma_hour)\n",
    "        if X_hour.shape[0] == 0:\n",
    "            continue\n",
    "        y_hour = to_binary_target(y_hour_cont, POSITIVE_THRESHOLD)\n",
    "        yield entry[\"fire_name\"], t, X_hour, y_hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3e07d",
   "metadata": {},
   "source": [
    "## 6) Dataset pass 1 (sample/class stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_samples = 0\n",
    "n_train_samples = 0\n",
    "n_test_samples = 0\n",
    "n_hours_used = 0\n",
    "n_train_hours = 0\n",
    "n_test_hours = 0\n",
    "\n",
    "train_pos = 0\n",
    "train_neg = 0\n",
    "test_pos = 0\n",
    "test_neg = 0\n",
    "\n",
    "if RUN_DATA_STATS_SECTION:\n",
    "    if not train_fire_entries or not test_fire_entries:\n",
    "        raise RuntimeError(\"Data stats section requires fire discovery section to be enabled.\")\n",
    "\n",
    "    for entry in train_fire_entries:\n",
    "        for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "            n_hours_used += 1\n",
    "            n_train_hours += 1\n",
    "            n_rows = X_hour.shape[0]\n",
    "            n_total_samples += n_rows\n",
    "            n_train_samples += n_rows\n",
    "            train_pos += int(y_hour.sum())\n",
    "            train_neg += int(y_hour.shape[0] - y_hour.sum())\n",
    "\n",
    "    for entry in test_fire_entries:\n",
    "        for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "            n_hours_used += 1\n",
    "            n_test_hours += 1\n",
    "            n_rows = X_hour.shape[0]\n",
    "            n_total_samples += n_rows\n",
    "            n_test_samples += n_rows\n",
    "            test_pos += int(y_hour.sum())\n",
    "            test_neg += int(y_hour.shape[0] - y_hour.sum())\n",
    "\n",
    "    if n_train_samples == 0:\n",
    "        raise RuntimeError(\"No training samples from train-fire set.\")\n",
    "    if n_test_samples == 0:\n",
    "        raise RuntimeError(\"No testing samples from test-fire set.\")\n",
    "\n",
    "    train_pos_rate = train_pos / n_train_samples\n",
    "    test_pos_rate = test_pos / n_test_samples\n",
    "\n",
    "    print(\"train fires:\", [e[\"fire_name\"] for e in train_fire_entries])\n",
    "    print(\"test fires:\", [e[\"fire_name\"] for e in test_fire_entries])\n",
    "    print(\"hours used total:\", n_hours_used)\n",
    "    print(\"hours used train:\", n_train_hours)\n",
    "    print(\"hours used test:\", n_test_hours)\n",
    "    print(\"total samples:\", n_total_samples)\n",
    "    print(\"train samples:\", n_train_samples)\n",
    "    print(\"test samples:\", n_test_samples)\n",
    "    print(\"observed train sample fraction:\", n_train_samples / n_total_samples)\n",
    "    print(\"observed test sample fraction:\", n_test_samples / n_total_samples)\n",
    "    print(\"train positives:\", train_pos, \"train negatives:\", train_neg, \"train pos rate:\", train_pos_rate)\n",
    "    print(\"test positives:\", test_pos, \"test negatives:\", test_neg, \"test pos rate:\", test_pos_rate)\n",
    "else:\n",
    "    train_pos_rate = None\n",
    "    test_pos_rate = None\n",
    "    print(\"Skipped data stats section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0644f8",
   "metadata": {},
   "source": [
    "## 7) Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77819a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mean = np.zeros(N_FEATURES, dtype=np.float64)\n",
    "feature_std = np.ones(N_FEATURES, dtype=np.float64)\n",
    "feature_std_safe = np.ones(N_FEATURES, dtype=np.float64)\n",
    "n_norm_samples = 0\n",
    "n_zero_std_features = 0\n",
    "\n",
    "\n",
    "def normalize_X(X):\n",
    "    return X\n",
    "\n",
    "\n",
    "if RUN_NORMALIZATION_SECTION:\n",
    "    if NORMALIZE_FEATURES:\n",
    "        if not train_fire_entries:\n",
    "            raise RuntimeError(\"Normalization section requires fire discovery section to be enabled.\")\n",
    "\n",
    "        feature_sum = np.zeros(N_FEATURES, dtype=np.float64)\n",
    "        feature_sq_sum = np.zeros(N_FEATURES, dtype=np.float64)\n",
    "\n",
    "        for entry in train_fire_entries:\n",
    "            for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "                X_block = X_hour.astype(np.float64)\n",
    "                feature_sum += X_block.sum(axis=0)\n",
    "                feature_sq_sum += np.square(X_block).sum(axis=0)\n",
    "                n_norm_samples += X_block.shape[0]\n",
    "\n",
    "        if n_norm_samples == 0:\n",
    "            raise RuntimeError(\"No training samples available for normalization stats.\")\n",
    "\n",
    "        feature_mean = feature_sum / n_norm_samples\n",
    "        feature_var = (feature_sq_sum / n_norm_samples) - np.square(feature_mean)\n",
    "        feature_var = np.maximum(feature_var, 0.0)\n",
    "        feature_std = np.sqrt(feature_var)\n",
    "        feature_std_safe = np.where(feature_std > 0.0, feature_std, 1.0)\n",
    "        n_zero_std_features = int((feature_std == 0.0).sum())\n",
    "\n",
    "        def normalize_X(X):\n",
    "            return (X - feature_mean) / feature_std_safe\n",
    "\n",
    "        print(\"normalization mode:\", \"zscore_from_train_fires\")\n",
    "        print(\"normalization samples:\", n_norm_samples)\n",
    "        print(\"zero-std feature count:\", n_zero_std_features)\n",
    "    else:\n",
    "        print(\"normalization mode:\", \"none (NORMALIZE_FEATURES=False)\")\n",
    "else:\n",
    "    print(\"Skipped normalization section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be899c3",
   "metadata": {},
   "source": [
    "## 8) Train logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e63cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = None\n",
    "trained = False\n",
    "intercept = None\n",
    "coef_map = {}\n",
    "\n",
    "if RUN_TRAINING_SECTION:\n",
    "    if not train_fire_entries:\n",
    "        raise RuntimeError(\"Training section requires fire discovery section to be enabled.\")\n",
    "\n",
    "    clf = SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        penalty=\"l2\",\n",
    "        alpha=1e-4,\n",
    "        max_iter=1,\n",
    "        tol=None,\n",
    "        random_state=None,\n",
    "    )\n",
    "\n",
    "    classes = np.array([0, 1], dtype=np.int32)\n",
    "\n",
    "    for entry in train_fire_entries:\n",
    "        for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "            X_train = normalize_X(X_hour.astype(np.float64))\n",
    "            y_train = y_hour\n",
    "\n",
    "            if not trained:\n",
    "                clf.partial_fit(X_train, y_train, classes=classes)\n",
    "                trained = True\n",
    "            else:\n",
    "                clf.partial_fit(X_train, y_train)\n",
    "\n",
    "    if not trained:\n",
    "        raise RuntimeError(\"Model did not receive training data from train-fire set.\")\n",
    "\n",
    "    intercept = float(clf.intercept_[0])\n",
    "    coef_std = clf.coef_.ravel()\n",
    "    coef_map = {name: float(val) for name, val in zip(FEATURE_NAMES, coef_std)}\n",
    "\n",
    "    print(\"intercept:\", intercept)\n",
    "    print(\"coefficient count:\", len(coef_map))\n",
    "else:\n",
    "    print(\"Skipped training section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d699d",
   "metadata": {},
   "source": [
    "## 9) Evaluate on held-out test fires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_test = 0\n",
    "count_test_eval = 0\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "test_accuracy_overall = None\n",
    "test_positive_accuracy = None\n",
    "test_negative_accuracy = None\n",
    "\n",
    "if RUN_EVALUATION_SECTION:\n",
    "    if clf is None or not trained:\n",
    "        raise RuntimeError(\"Evaluation section requires training section to run first.\")\n",
    "    if not test_fire_entries:\n",
    "        raise RuntimeError(\"Evaluation section requires fire discovery section to be enabled.\")\n",
    "\n",
    "    for entry in test_fire_entries:\n",
    "        for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "            X_test = normalize_X(X_hour.astype(np.float64))\n",
    "            y_test = y_hour\n",
    "\n",
    "            prob_test = clf.predict_proba(X_test)[:, 1]\n",
    "            y_hat = (prob_test >= CLASSIFICATION_PROB_THRESHOLD).astype(np.int32)\n",
    "\n",
    "            correct_test += int((y_hat == y_test).sum())\n",
    "            count_test_eval += y_test.shape[0]\n",
    "\n",
    "            tp += int(((y_hat == 1) & (y_test == 1)).sum())\n",
    "            fp += int(((y_hat == 1) & (y_test == 0)).sum())\n",
    "            fn += int(((y_hat == 0) & (y_test == 1)).sum())\n",
    "            tn += int(((y_hat == 0) & (y_test == 0)).sum())\n",
    "\n",
    "    if count_test_eval == 0:\n",
    "        raise RuntimeError(\"No valid evaluation samples in full test-fire set.\")\n",
    "\n",
    "    test_accuracy_overall = float(correct_test / count_test_eval)\n",
    "    test_positive_accuracy = float(tp / (tp + fn)) if (tp + fn) > 0 else None\n",
    "    test_negative_accuracy = float(tn / (tn + fp)) if (tn + fp) > 0 else None\n",
    "\n",
    "    print(\"test evaluation samples:\", count_test_eval)\n",
    "    print(\"test accuracy overall:\", test_accuracy_overall)\n",
    "    print(\"test positive accuracy:\", test_positive_accuracy)\n",
    "    print(\"test negative accuracy:\", test_negative_accuracy)\n",
    "    print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "else:\n",
    "    print(\"Skipped evaluation section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3916e",
   "metadata": {},
   "source": [
    "## 10) Summary tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ea6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = None\n",
    "\n",
    "if RUN_SUMMARY_SECTION:\n",
    "    summary_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"model\": \"logistic_regression\",\n",
    "                \"target\": \"center_confidence_t+1_binary\",\n",
    "                \"fires_used_count\": len(fire_entries),\n",
    "                \"fires_used\": [e[\"fire_name\"] for e in fire_entries],\n",
    "                \"train_fires_count\": len(train_fire_entries),\n",
    "                \"test_fires_count\": len(test_fire_entries),\n",
    "                \"train_fires\": [e[\"fire_name\"] for e in train_fire_entries],\n",
    "                \"test_fires\": [e[\"fire_name\"] for e in test_fire_entries],\n",
    "                \"positive_threshold\": POSITIVE_THRESHOLD,\n",
    "                \"total_samples\": int(n_total_samples),\n",
    "                \"train_samples\": int(n_train_samples),\n",
    "                \"test_samples\": int(n_test_samples),\n",
    "                \"hours_used\": int(n_hours_used),\n",
    "                \"train_hours\": int(n_train_hours),\n",
    "                \"test_hours\": int(n_test_hours),\n",
    "                \"train_positive_rate\": train_pos_rate,\n",
    "                \"test_positive_rate\": test_pos_rate,\n",
    "                \"test_accuracy_overall\": test_accuracy_overall,\n",
    "                \"test_positive_accuracy\": test_positive_accuracy,\n",
    "                \"test_negative_accuracy\": test_negative_accuracy,\n",
    "                \"tp\": int(tp),\n",
    "                \"fp\": int(fp),\n",
    "                \"fn\": int(fn),\n",
    "                \"tn\": int(tn),\n",
    "                \"classification_prob_threshold\": CLASSIFICATION_PROB_THRESHOLD,\n",
    "                \"feature_normalization\": \"zscore_from_train_fires\" if NORMALIZE_FEATURES else \"none\",\n",
    "                \"intercept\": intercept,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    summary_df\n",
    "else:\n",
    "    print(\"Skipped summary table section.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db244bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_breakdown_df = None\n",
    "\n",
    "if RUN_SUMMARY_SECTION:\n",
    "    confusion_breakdown_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"true_positives\": int(tp),\n",
    "                \"false_positives\": int(fp),\n",
    "                \"false_negatives\": int(fn),\n",
    "                \"true_negatives\": int(tn),\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    confusion_breakdown_df\n",
    "else:\n",
    "    print(\"Skipped confusion breakdown table.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d88525",
   "metadata": {},
   "source": [
    "## 11) Validation-fire PR curve (threshold selection)\n",
    "\n",
    "Use this section to choose `CLASSIFICATION_PROB_THRESHOLD` from validation fires (not from test fires).\n",
    "\n",
    "- Split method: fire-level split inside the current `train_fire_entries`\n",
    "- Output: validation PR curve + `val_pr_df` sorted by `f1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31deeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation-fire PR curve + best-threshold table (sorted by F1)\n",
    "\n",
    "# Validation split config.\n",
    "VALIDATION_FIRES = \"auto\"  # \"auto\" or explicit list like [\"Creek\", \"Dixie\"]\n",
    "VALIDATION_FRACTION_OF_TRAIN_FIRES = 0.30\n",
    "VALIDATION_SPLIT_SEED = 123\n",
    "VAL_PR_THRESHOLDS = np.linspace(0.0, 1.0, 1001)\n",
    "\n",
    "# Split current train fires into inner-train and validation by full fires.\n",
    "train_names = [e[\"fire_name\"] for e in train_fire_entries]\n",
    "if len(train_names) < 2:\n",
    "    raise RuntimeError(\"Need at least 2 train fires to make a validation split.\")\n",
    "\n",
    "if VALIDATION_FIRES == \"auto\":\n",
    "    rng = np.random.default_rng(VALIDATION_SPLIT_SEED)\n",
    "    perm = list(np.array(train_names)[rng.permutation(len(train_names))])\n",
    "    n_val = max(1, int(round(len(perm) * VALIDATION_FRACTION_OF_TRAIN_FIRES)))\n",
    "    n_val = min(n_val, len(perm) - 1)\n",
    "    val_name_set = set(perm[:n_val])\n",
    "else:\n",
    "    if not isinstance(VALIDATION_FIRES, (list, tuple, set)):\n",
    "        raise ValueError('VALIDATION_FIRES must be \"auto\" or list/tuple/set of fire names.')\n",
    "    val_name_set = {str(x) for x in VALIDATION_FIRES}\n",
    "\n",
    "inner_train_entries = [e for e in train_fire_entries if e[\"fire_name\"] not in val_name_set]\n",
    "val_entries = [e for e in train_fire_entries if e[\"fire_name\"] in val_name_set]\n",
    "\n",
    "if not inner_train_entries or not val_entries:\n",
    "    raise RuntimeError(\"Validation split produced empty inner-train or validation fire set.\")\n",
    "\n",
    "print(\"inner-train fires:\", [e[\"fire_name\"] for e in inner_train_entries])\n",
    "print(\"validation fires:\", [e[\"fire_name\"] for e in val_entries])\n",
    "\n",
    "# Fit normalization from inner-train only.\n",
    "if NORMALIZE_FEATURES:\n",
    "    s = np.zeros(N_FEATURES, dtype=np.float64)\n",
    "    ss = np.zeros(N_FEATURES, dtype=np.float64)\n",
    "    n = 0\n",
    "    for entry in inner_train_entries:\n",
    "        for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "            Xb = X_hour.astype(np.float64)\n",
    "            s += Xb.sum(axis=0)\n",
    "            ss += np.square(Xb).sum(axis=0)\n",
    "            n += Xb.shape[0]\n",
    "\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\"No inner-train samples available for validation normalization.\")\n",
    "\n",
    "    mu = s / n\n",
    "    var = np.maximum((ss / n) - np.square(mu), 0.0)\n",
    "    std = np.sqrt(var)\n",
    "    std_safe = np.where(std > 0.0, std, 1.0)\n",
    "\n",
    "    def val_normalize_X(X):\n",
    "        return (X - mu) / std_safe\n",
    "else:\n",
    "\n",
    "    def val_normalize_X(X):\n",
    "        return X.astype(np.float64)\n",
    "\n",
    "# Train temporary validation model on inner-train fires.\n",
    "val_clf = SGDClassifier(\n",
    "    loss=\"log_loss\",\n",
    "    penalty=\"l2\",\n",
    "    alpha=1e-4,\n",
    "    max_iter=1,\n",
    "    tol=None,\n",
    "    random_state=None,\n",
    ")\n",
    "\n",
    "classes = np.array([0, 1], dtype=np.int32)\n",
    "val_trained = False\n",
    "\n",
    "for entry in inner_train_entries:\n",
    "    for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "        X_train = val_normalize_X(X_hour)\n",
    "        y_train = y_hour\n",
    "        if not val_trained:\n",
    "            val_clf.partial_fit(X_train, y_train, classes=classes)\n",
    "            val_trained = True\n",
    "        else:\n",
    "            val_clf.partial_fit(X_train, y_train)\n",
    "\n",
    "if not val_trained:\n",
    "    raise RuntimeError(\"Validation model did not receive inner-train samples.\")\n",
    "\n",
    "# Compute precision-recall on validation fires.\n",
    "val_pr_tp = np.zeros(VAL_PR_THRESHOLDS.shape[0], dtype=np.int64)\n",
    "val_pr_fp = np.zeros(VAL_PR_THRESHOLDS.shape[0], dtype=np.int64)\n",
    "val_total_pos = 0\n",
    "val_total_neg = 0\n",
    "\n",
    "for entry in val_entries:\n",
    "    for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "        X_val = val_normalize_X(X_hour)\n",
    "        y_val = y_hour.astype(np.int32)\n",
    "\n",
    "        prob = val_clf.predict_proba(X_val)[:, 1]\n",
    "        pos = y_val == 1\n",
    "        val_total_pos += int(pos.sum())\n",
    "        val_total_neg += int((~pos).sum())\n",
    "\n",
    "        pred = prob[:, None] >= VAL_PR_THRESHOLDS[None, :]\n",
    "        val_pr_tp += (pred & pos[:, None]).sum(axis=0).astype(np.int64)\n",
    "        val_pr_fp += (pred & (~pos)[:, None]).sum(axis=0).astype(np.int64)\n",
    "\n",
    "if val_total_pos == 0:\n",
    "    raise RuntimeError(\"No positive samples in validation set; cannot compute precision/recall.\")\n",
    "\n",
    "val_pr_fn = val_total_pos - val_pr_tp\n",
    "val_pr_tn = val_total_neg - val_pr_fp\n",
    "\n",
    "val_pr_precision = np.where((val_pr_tp + val_pr_fp) > 0, val_pr_tp / (val_pr_tp + val_pr_fp), 1.0)\n",
    "val_pr_recall = val_pr_tp / val_total_pos\n",
    "val_pr_f1 = np.where(\n",
    "    (val_pr_precision + val_pr_recall) > 0,\n",
    "    2 * val_pr_precision * val_pr_recall / (val_pr_precision + val_pr_recall),\n",
    "    0.0,\n",
    ")\n",
    "\n",
    "val_pr_df = pd.DataFrame(\n",
    "    {\n",
    "        \"threshold\": VAL_PR_THRESHOLDS,\n",
    "        \"precision\": val_pr_precision,\n",
    "        \"recall\": val_pr_recall,\n",
    "        \"f1\": val_pr_f1,\n",
    "        \"tp\": val_pr_tp,\n",
    "        \"fp\": val_pr_fp,\n",
    "        \"fn\": val_pr_fn,\n",
    "        \"tn\": val_pr_tn,\n",
    "    }\n",
    ").sort_values(\"f1\", ascending=False)\n",
    "\n",
    "best_val = val_pr_df.iloc[0]\n",
    "val_baseline = val_total_pos / (val_total_pos + val_total_neg)\n",
    "\n",
    "print(\"validation positive rate (baseline precision):\", float(val_baseline))\n",
    "print(\"best threshold by F1 (validation):\", float(best_val[\"threshold\"]))\n",
    "print(\n",
    "    \"best precision/recall/F1:\",\n",
    "    float(best_val[\"precision\"]),\n",
    "    float(best_val[\"recall\"]),\n",
    "    float(best_val[\"f1\"]),\n",
    ")\n",
    "\n",
    "val_pr_plot_df = val_pr_df.sort_values(\"recall\")\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(val_pr_plot_df[\"recall\"], val_pr_plot_df[\"precision\"], linewidth=2)\n",
    "plt.hlines(\n",
    "    val_baseline,\n",
    "    0,\n",
    "    1,\n",
    "    linestyles=\"dashed\",\n",
    "    colors=\"gray\",\n",
    "    label=f\"baseline (pos rate={val_baseline:.3f})\",\n",
    ")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (Validation Fires)\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Top thresholds by F1 for manual threshold selection.\n",
    "val_pr_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d6f20",
   "metadata": {},
   "source": [
    "## 11) Precision-Recall curve (test split)\n",
    "\n",
    "Precision-recall is often more informative than ROC when positives are rare.\n",
    "\n",
    "- Precision = `TP / (TP + FP)`\n",
    "- Recall = `TP / (TP + FN)`\n",
    "\n",
    "This sweeps the *classification probability threshold* (not the label threshold) over the held-out test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df = None\n",
    "\n",
    "if RUN_PR_SECTION:\n",
    "    if clf is None or not trained:\n",
    "        raise RuntimeError(\"Precision-recall section requires training section to run first.\")\n",
    "    if not test_fire_entries:\n",
    "        raise RuntimeError(\"Precision-recall section requires fire discovery section to be enabled.\")\n",
    "\n",
    "    PR_THRESHOLDS = np.linspace(0.0, 1.0, 1001)\n",
    "\n",
    "    pr_tp = np.zeros(PR_THRESHOLDS.shape[0], dtype=np.int64)\n",
    "    pr_fp = np.zeros(PR_THRESHOLDS.shape[0], dtype=np.int64)\n",
    "\n",
    "    pr_total_pos = 0\n",
    "    pr_total_neg = 0\n",
    "\n",
    "    for entry in test_fire_entries:\n",
    "        for fire_name, t, X_hour, y_hour in iter_fire_hour_samples(entry):\n",
    "            X_test = normalize_X(X_hour.astype(np.float64))\n",
    "            y_test = y_hour.astype(np.int32)\n",
    "\n",
    "            prob = clf.predict_proba(X_test)[:, 1]\n",
    "            pos = y_test == 1\n",
    "            pr_total_pos += int(pos.sum())\n",
    "            pr_total_neg += int((~pos).sum())\n",
    "\n",
    "            pred = prob[:, None] >= PR_THRESHOLDS[None, :]\n",
    "            pr_tp += (pred & pos[:, None]).sum(axis=0).astype(np.int64)\n",
    "            pr_fp += (pred & (~pos)[:, None]).sum(axis=0).astype(np.int64)\n",
    "\n",
    "    if pr_total_pos == 0:\n",
    "        raise RuntimeError(\"No positive samples in the test-fire set; cannot compute precision/recall.\")\n",
    "\n",
    "    pr_fn = pr_total_pos - pr_tp\n",
    "    pr_tn = pr_total_neg - pr_fp\n",
    "\n",
    "    pr_precision = np.where((pr_tp + pr_fp) > 0, pr_tp / (pr_tp + pr_fp), 1.0)\n",
    "    pr_recall = pr_tp / pr_total_pos\n",
    "\n",
    "    pr_f1 = np.where(\n",
    "        (pr_precision + pr_recall) > 0,\n",
    "        2 * pr_precision * pr_recall / (pr_precision + pr_recall),\n",
    "        0.0,\n",
    "    )\n",
    "\n",
    "    pr_df = pd.DataFrame(\n",
    "        {\n",
    "            \"threshold\": PR_THRESHOLDS,\n",
    "            \"precision\": pr_precision,\n",
    "            \"recall\": pr_recall,\n",
    "            \"f1\": pr_f1,\n",
    "            \"tp\": pr_tp,\n",
    "            \"fp\": pr_fp,\n",
    "            \"fn\": pr_fn,\n",
    "            \"tn\": pr_tn,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    best = pr_df.iloc[int(pr_df[\"f1\"].idxmax())]\n",
    "    baseline = pr_total_pos / (pr_total_pos + pr_total_neg)\n",
    "\n",
    "    print(\"test-fire positive rate (baseline precision at recall=1):\", float(baseline))\n",
    "    print(\"best threshold by F1:\", float(best[\"threshold\"]))\n",
    "    print(\"precision:\", float(best[\"precision\"]), \"recall:\", float(best[\"recall\"]), \"f1:\", float(best[\"f1\"]))\n",
    "\n",
    "    pr_plot_df = pr_df.sort_values(\"recall\")\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(pr_plot_df[\"recall\"], pr_plot_df[\"precision\"], linewidth=2)\n",
    "    plt.hlines(baseline, 0, 1, linestyles=\"dashed\", colors=\"gray\", label=f\"baseline (pos rate={baseline:.3f})\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"Recall (TP / (TP+FN))\")\n",
    "    plt.ylabel(\"Precision (TP / (TP+FP))\")\n",
    "    plt.title(\"Precision-Recall Curve (Test-Fire Set)\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    pr_df.sort_values(\"f1\", ascending=False).head(12)\n",
    "else:\n",
    "    print(\"Skipped precision-recall section.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d73a21-f99e-44bd-a6ca-f0569cbe9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df.sort_values(\"f1\", ascending=False).head(12)\n",
    "pr_df.head(501)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52ef63",
   "metadata": {},
   "source": [
    "## 12) Coefficients (top features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = None\n",
    "coef_top = None\n",
    "\n",
    "if RUN_COEFFICIENT_SECTION:\n",
    "    if not coef_map:\n",
    "        raise RuntimeError(\"Coefficient section requires training section to run first.\")\n",
    "\n",
    "    coef_rows = []\n",
    "    for feat, coef in coef_map.items():\n",
    "        coef_rows.append(\n",
    "            {\n",
    "                \"feature\": feat,\n",
    "                \"coef\": coef,\n",
    "                \"odds_ratio\": float(np.exp(coef)),\n",
    "                \"abs_coef\": abs(coef),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    coef_df = pd.DataFrame(coef_rows).sort_values(\"abs_coef\", ascending=False)\n",
    "    coef_top = coef_df.head(20).drop(columns=[\"abs_coef\"])\n",
    "    coef_top\n",
    "else:\n",
    "    print(\"Skipped coefficient table section.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_COEFFICIENT_SECTION:\n",
    "    if coef_df is None:\n",
    "        raise RuntimeError(\"Coefficient plot section requires coefficient table generation.\")\n",
    "\n",
    "    coef_plot_df = coef_df.head(10).iloc[::-1]\n",
    "    colors = [\"#1f77b4\" if c >= 0 else \"#d62728\" for c in coef_plot_df[\"coef\"]]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(coef_plot_df[\"feature\"], coef_plot_df[\"coef\"], color=colors)\n",
    "    plt.axvline(0.0, color=\"black\", linewidth=0.8)\n",
    "    plt.title(\"Top logistic coefficients\")\n",
    "    plt.xlabel(\"Coefficient (log-odds)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipped coefficient plot section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66582e05",
   "metadata": {},
   "source": [
    "## 13) JSON-style report object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ceea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = None\n",
    "\n",
    "if RUN_REPORT_SECTION:\n",
    "    report = {\n",
    "        \"model\": \"logistic_regression\",\n",
    "        \"target\": \"center_confidence_t_plus_1_binary\",\n",
    "        \"fires_used\": [e[\"fire_name\"] for e in fire_entries],\n",
    "        \"train_fires\": [e[\"fire_name\"] for e in train_fire_entries],\n",
    "        \"test_fires\": [e[\"fire_name\"] for e in test_fire_entries],\n",
    "        \"thresholds\": {\n",
    "            \"positive_confidence\": POSITIVE_THRESHOLD,\n",
    "            \"classification_probability\": CLASSIFICATION_PROB_THRESHOLD,\n",
    "        },\n",
    "        \"split\": {\n",
    "            \"method\": \"fire_holdout\",\n",
    "            \"train_fire_count\": len(train_fire_entries),\n",
    "            \"test_fire_count\": len(test_fire_entries),\n",
    "            \"train_fire_fraction_target\": FIRE_TRAIN_FRACTION,\n",
    "            \"split_seed\": FIRE_SPLIT_SEED,\n",
    "        },\n",
    "        \"feature_order\": FEATURE_NAMES,\n",
    "        \"feature_normalization\": {\n",
    "            \"enabled\": NORMALIZE_FEATURES,\n",
    "            \"method\": \"zscore_from_train_fires\" if NORMALIZE_FEATURES else \"none\",\n",
    "            \"samples_used\": int(n_norm_samples),\n",
    "            \"zero_std_feature_count\": int(n_zero_std_features),\n",
    "        },\n",
    "        \"metrics_test\": {\n",
    "            \"test_accuracy_overall\": test_accuracy_overall,\n",
    "            \"test_positive_accuracy\": test_positive_accuracy,\n",
    "            \"test_negative_accuracy\": test_negative_accuracy,\n",
    "            \"tp\": int(tp),\n",
    "            \"fp\": int(fp),\n",
    "            \"fn\": int(fn),\n",
    "            \"tn\": int(tn),\n",
    "        },\n",
    "        \"class_balance\": {\n",
    "            \"train_positive_rate\": train_pos_rate,\n",
    "            \"test_positive_rate\": test_pos_rate,\n",
    "            \"train_positives\": int(train_pos),\n",
    "            \"train_negatives\": int(train_neg),\n",
    "            \"test_positives\": int(test_pos),\n",
    "            \"test_negatives\": int(test_neg),\n",
    "        },\n",
    "        \"coefficients\": {\n",
    "            \"intercept\": intercept,\n",
    "            \"values\": coef_map,\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"total_samples\": int(n_total_samples),\n",
    "            \"train_samples\": int(n_train_samples),\n",
    "            \"test_samples\": int(n_test_samples),\n",
    "            \"hours_used\": int(n_hours_used),\n",
    "            \"train_hours\": int(n_train_hours),\n",
    "            \"test_hours\": int(n_test_hours),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    print(\"Report keys:\", list(report.keys()))\n",
    "else:\n",
    "    print(\"Skipped report section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993c0e8",
   "metadata": {},
   "source": [
    "## 14) Notes and constraints\n",
    "\n",
    "- GOES confidence is a proxy signal, not direct flame-front geometry.\n",
    "- This is a linear decision-boundary model (logistic regression), so non-linear effects are not modeled.\n",
    "- Features use center + 8-neighbor cell data at current hour.\n",
    "- Wind direction is encoded as `sin`/`cos` (from RTMA degree values), not passed as raw degrees.\n",
    "- Split is by complete fires: train and test sets use different fires (no within-fire sample split).\n",
    "- Features are z-score normalized using train-fire statistics only, then applied to both train and test data.\n",
    "- `test_positive_accuracy` = `TP / (TP + FN)` and `test_negative_accuracy` = `TN / (TN + FP)`.\n",
    "- Runtime can be substantial because this uses all samples across full train/test fire groups.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
